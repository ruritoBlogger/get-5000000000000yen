{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import training, iterators, optimizers, serializers, Chain\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    " \n",
    "from chainer.training import extensions\n",
    "from chainer.datasets import tuple_dataset\n",
    "from chainer import optimizers, Chain, dataset, datasets, iterators\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_read( file_name, key):\n",
    "    teachers = np.array([] )\n",
    "    answers =  np.array([] )\n",
    "\n",
    "    f = open( file_name, mode = \"r\" )\n",
    "    f_string = f.readlines()\n",
    "    data = np.array([] )\n",
    "    \n",
    "    for i in range( 0, len( f_string ) ):\n",
    "        #引数を用いて正解ラベルを振り分ける\n",
    "        tmp_data = np.zeros(10)\n",
    "        if( i != 0 and i%key == 0 ):\n",
    "            teachers = np.append( teachers, data)\n",
    "            data = np.array([] )\n",
    "            for j in f_string[i].replace( \"\\n\", \"\" ):\n",
    "                tmp_data[int(j)] += 1\n",
    "            answers = np.append( answers, tmp_data )\n",
    "        else:\n",
    "            for j in f_string[i].replace( \"\\n\", \"\" ):\n",
    "                tmp_data[int(j)] += 1\n",
    "                data = np.append( data, tmp_data )\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    teachers = teachers.astype( np.float32 )\n",
    "    answers = answers.astype( np.float32 )\n",
    "    \n",
    "    teachers = np.reshape( teachers, ( int( len( teachers ) / 10 / key ), key, 10 ) )\n",
    "    \n",
    "    answers = np.reshape( answers, ( int( len( answers ) / 10 ) , 10 ) )\n",
    "    return teachers, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teachers, answers = data_read( 'numbers.txt', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2667\n",
      "1111\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 2. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]]\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(len(teachers))\n",
    "print(len(answers))\n",
    "print(teachers[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ニューラルネットワークの構築。\n",
    "class RNN(Chain):\n",
    "    \n",
    "    def __init__(self, n_hidden, n_output):\n",
    "        super(RNN, self).__init__(\n",
    "            l1=L.LSTM(None, n_hidden),\n",
    "            l2=L.Linear(None, n_output),\n",
    "        )\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.l1.reset_state()\n",
    "        \n",
    "    def __call__(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        loss = F.mean_squared_error(y, t)\n",
    "        #accuracy = F.accuracy(y, t)\n",
    "        #chainer.reporter.report({'accuracy':accuracy},self)\n",
    "        chainer.reporter.report({'loss':loss},self)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if train:\n",
    "            h1 = F.dropout(self.l1(x),ratio = 0.5)\n",
    "        else:\n",
    "            h1 = self.l1(x)\n",
    "        return self.l2(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Updaterを拡張する\n",
    "from chainer import Variable, reporter\n",
    "\n",
    "class LSTMUpdater(training.StandardUpdater):\n",
    "    def __init__(self, data_iter, optimizer, device=None):\n",
    "        super(LSTMUpdater,self).__init__(data_iter, optimizer, device=None)\n",
    "        self.device = device\n",
    "        \n",
    "    def update_core(self):\n",
    "        data_iter = self.get_iterator(\"main\")\n",
    "        optimizer = self.get_optimizer(\"main\")\n",
    "        \n",
    "        batch = data_iter.__next__()\n",
    "        x_batch, t_batch = chainer.dataset.concat_examples(batch, self.device)\n",
    "        \n",
    "        optimizer.target.reset_state()           \n",
    "        optimizer.target.cleargrads()\n",
    "        #loss = optimizer.target(Variable(x_batch), Variable(t_batch))\n",
    "        loss = optimizer.target(x_batch, t_batch)\n",
    "        loss.backward()\n",
    "        loss.unchain_backward()                  \n",
    "        optimizer.update() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           0.358723    0.33355                                                        0.108125      \n",
      "\u001b[J2           0.328003    0.319141                                                       0.400148      \n",
      "\u001b[J3           0.308625    0.309541                                                       0.736793      \n",
      "\u001b[J4           0.298308    0.309983                                                       1.09959       \n",
      "\u001b[J5           0.290337    0.308601                                                       1.42175       \n",
      "\u001b[J6           0.284335    0.308748                                                       1.83863       \n",
      "\u001b[J7           0.281414    0.306491                                                       2.17969       \n",
      "\u001b[J8           0.27684     0.30461                                                        2.56712       \n",
      "\u001b[J9           0.276264    0.308157                                                       2.8966        \n",
      "\u001b[J10          0.274115    0.3051                                                         3.24819       \n",
      "\u001b[J11          0.275799    0.30288                                                        3.59705       \n",
      "\u001b[J12          0.272086    0.30227                                                        3.96543       \n",
      "\u001b[J13          0.272193    0.300366                                                       4.19168       \n",
      "\u001b[J14          0.272077    0.300163                                                       4.53025       \n",
      "\u001b[J15          0.270735    0.29787                                                        4.8891        \n",
      "\u001b[J16          0.271053    0.298022                                                       5.23918       \n",
      "\u001b[J17          0.269448    0.296608                                                       5.59481       \n",
      "\u001b[J18          0.269492    0.295145                                                       5.97815       \n",
      "\u001b[J19          0.269195    0.296294                                                       6.24695       \n",
      "\u001b[J20          0.26822     0.295407                                                       6.59841       \n",
      "\u001b[J21          0.268776    0.294516                                                       6.96036       \n",
      "\u001b[J22          0.267462    0.291901                                                       7.32488       \n",
      "\u001b[J23          0.26794     0.290153                                                       7.70985       \n",
      "\u001b[J24          0.267792    0.291282                                                       8.01292       \n",
      "\u001b[J25          0.26758     0.289766                                                       8.32922       \n",
      "\u001b[J26          0.268387    0.289118                                                       8.68014       \n",
      "\u001b[J27          0.266392    0.288078                                                       9.0269        \n",
      "\u001b[J28          0.266726    0.286888                                                       9.361         \n",
      "\u001b[J29          0.26606     0.288182                                                       9.78897       \n",
      "\u001b[J30          0.26592     0.28704                                                        10.0795       \n",
      "\u001b[J31          0.266929    0.287315                                                       10.369        \n",
      "\u001b[J32          0.265399    0.285776                                                       10.756        \n",
      "\u001b[J33          0.265618    0.284205                                                       11.1308       \n",
      "\u001b[J34          0.266674    0.284986                                                       11.5649       \n",
      "\u001b[J35          0.264675    0.284609                                                       11.9147       \n",
      "\u001b[J36          0.266793    0.284096                                                       12.1781       \n",
      "\u001b[J37          0.26421     0.284451                                                       12.5364       \n",
      "\u001b[J38          0.26594     0.281723                                                       12.8974       \n",
      "\u001b[J39          0.265138    0.283444                                                       13.2438       \n",
      "\u001b[J40          0.265698    0.281591                                                       13.7078       \n",
      "\u001b[J41          0.265176    0.282618                                                       14.0112       \n",
      "\u001b[J42          0.264502    0.281899                                                       14.3145       \n",
      "\u001b[J43          0.264671    0.280189                                                       14.6841       \n",
      "\u001b[J44          0.265063    0.281214                                                       15.0139       \n",
      "\u001b[J45          0.263998    0.279848                                                       15.5254       \n",
      "\u001b[J46          0.2653      0.280134                                                       15.9088       \n",
      "\u001b[J47          0.263094    0.279967                                                       16.1586       \n",
      "\u001b[J48          0.264385    0.278997                                                       16.5295       \n",
      "\u001b[J49          0.264806    0.280183                                                       16.879        \n",
      "\u001b[J50          0.26408     0.279269                                                       17.224        \n",
      "\u001b[J51          0.263462    0.280029                                                       17.6714       \n",
      "\u001b[J52          0.262858    0.279223                                                       17.978        \n",
      "\u001b[J53          0.263051    0.278602                                                       18.2429       \n",
      "\u001b[J54          0.263393    0.28004                                                        18.6061       \n",
      "\u001b[J55          0.262704    0.278722                                                       18.9465       \n",
      "\u001b[J56          0.263093    0.279532                                                       19.3994       \n",
      "\u001b[J57          0.262367    0.278461                                                       19.7323       \n",
      "\u001b[J58          0.262044    0.277382                                                       20.0167       \n",
      "\u001b[J59          0.262733    0.279725                                                       20.3139       \n",
      "\u001b[J60          0.262541    0.279291                                                       20.6673       \n",
      "\u001b[J61          0.262953    0.279869                                                       21.0124       \n",
      "\u001b[J62          0.261536    0.279449                                                       21.464        \n",
      "\u001b[J63          0.262504    0.277258                                                       21.8162       \n",
      "\u001b[J64          0.261833    0.27855                                                        22.1024       \n",
      "\u001b[J65          0.262285    0.276937                                                       22.408        \n",
      "\u001b[J66          0.262463    0.277922                                                       22.7568       \n",
      "\u001b[J67          0.25996     0.277509                                                       23.1939       \n",
      "\u001b[J68          0.261952    0.276986                                                       23.548        \n",
      "\u001b[J69          0.262174    0.278601                                                       23.8988       \n",
      "\u001b[J70          0.260804    0.277962                                                       24.165        \n",
      "\u001b[J71          0.26198     0.278564                                                       24.5244       \n",
      "\u001b[J72          0.259838    0.277457                                                       24.8852       \n",
      "\u001b[J73          0.259943    0.27671                                                        25.3272       \n",
      "\u001b[J74          0.260851    0.27925                                                        25.7436       \n",
      "\u001b[J75          0.259414    0.278636                                                       26.0811       \n",
      "\u001b[J76          0.260893    0.280502                                                       26.424        \n",
      "\u001b[J77          0.258735    0.279426                                                       26.7709       \n",
      "\u001b[J78          0.25946     0.278576                                                       27.2388       \n",
      "\u001b[J79          0.259408    0.279969                                                       27.661        \n",
      "\u001b[J80          0.260149    0.27882                                                        27.9968       \n",
      "\u001b[J81          0.260677    0.279983                                                       28.3047       \n",
      "\u001b[J82          0.258757    0.277834                                                       28.6868       \n",
      "\u001b[J83          0.259651    0.276578                                                       29.0438       \n",
      "\u001b[J84          0.258514    0.278489                                                       29.5079       \n",
      "\u001b[J85          0.257333    0.278788                                                       29.8663       \n",
      "\u001b[J86          0.260295    0.280054                                                       30.1374       \n",
      "\u001b[J87          0.25758     0.278352                                                       30.4457       \n",
      "\u001b[J88          0.257385    0.277313                                                       30.8093       \n",
      "\u001b[J89          0.258339    0.2793                                                         31.2899       \n",
      "\u001b[J90          0.257379    0.27908                                                        31.6949       \n",
      "\u001b[J91          0.259458    0.280115                                                       32.0109       \n",
      "\u001b[J92          0.257362    0.278056                                                       32.3487       \n",
      "\u001b[J93          0.256986    0.277368                                                       32.7964       \n",
      "\u001b[J94          0.2572      0.278844                                                       33.2042       \n",
      "\u001b[J95          0.256184    0.278762                                                       33.6905       \n",
      "\u001b[J96          0.257442    0.279696                                                       34.0256       \n",
      "\u001b[J97          0.256268    0.27818                                                        34.3583       \n",
      "\u001b[J98          0.258022    0.277635                                                       34.7096       \n",
      "\u001b[J99          0.25755     0.2794                                                         35.0748       \n",
      "\u001b[J100         0.256479    0.280061                                                       35.5465       \n"
     ]
    }
   ],
   "source": [
    "#　教師データのtupleを作成する\n",
    "data = list(zip(teachers, answers))\n",
    "N = len(data)\n",
    "n_batchsize = 30\n",
    "n_epoch = 100\n",
    "\n",
    "#モデルを使う準備。オブジェクトを生成\n",
    "n_hidden = 10\n",
    "n_output = 10\n",
    "model = RNN(n_hidden, n_output)\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "#学習用データと検証用データに分ける\n",
    "train, test = chainer.datasets.split_dataset_random(data, int(N * 0.8))\n",
    "train_iter = chainer.iterators.SerialIterator(train, n_batchsize, shuffle=False)\n",
    "test_iter = chainer.iterators.SerialIterator(test, n_batchsize, repeat=False, shuffle=False)\n",
    "updater = LSTMUpdater(train_iter, optimizer, device=-1)\n",
    "trainer = training.Trainer(updater, (n_epoch, \"epoch\"), out=\"result\")\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.PrintReport( [\"epoch\", \"main/loss\", \"validation/main/loss\", \"main/accuracy\", \"validation/main/accuracy\", \"elapsed_time\"])) # エポック、学習損失、テスト損失、学習正解率、テスト正解率、経過時間\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
