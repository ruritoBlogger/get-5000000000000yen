{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import training, iterators, optimizers, serializers, Chain\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    " \n",
    "from chainer.training import extensions\n",
    "from chainer.datasets import tuple_dataset\n",
    "from chainer import optimizers, Chain, dataset, datasets, iterators\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_read( file_name, key):\n",
    "    teachers = []\n",
    "    answers =  []\n",
    "\n",
    "    f = open( file_name, mode = \"r\" )\n",
    "    f_string = f.readlines()\n",
    "    data = []\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range( 0, len( f_string ) ):\n",
    "        #引数を用いて正解ラベルを振り分ける\n",
    "        tmp_data = [0] * 10\n",
    "        for j in f_string[i].replace( \"\\n\", \"\" ):\n",
    "                tmp_data[int(j)] += 1\n",
    "               \n",
    "        if(False):\n",
    "            if( i < key-1):\n",
    "                data.append(tmp_data)\n",
    "            else:\n",
    "                teachers.append(data)\n",
    "                answers.append(tmp_data)\n",
    "                data.pop(0)\n",
    "                data.append(tmp_data)\n",
    "        \n",
    "            if( (i + 2)%100 == 0 ):\n",
    "                print(i/len(f_string))\n",
    "        else:\n",
    "            if( cnt == key ):\n",
    "                cnt = 0\n",
    "                teachers.append(data)\n",
    "                data = []\n",
    "                answers.append(tmp_data)\n",
    "            else:\n",
    "                cnt += 1\n",
    "                data.append(tmp_data)\n",
    "    f.close()\n",
    "    \n",
    "    #teachers = teachers.astype( np.float32 )\n",
    "    #answers = answers.astype( np.float32 )\n",
    "  \n",
    "    #整形\n",
    "    #teachers = np.reshape( teachers, ( int( len( teachers ) / 10 / key ), key, 10) )\n",
    "    #answers = np.reshape( answers, ( int( len( answers ) / 10 ) , 10 ) )\n",
    "    \n",
    "    data = []\n",
    "    for i in range(int( len( answers) / 10)):\n",
    "        tmp_data = []\n",
    "        tmp_teacher = []\n",
    "        for j in range(key):\n",
    "            tmp_teacher.append(teachers[i:i+10])\n",
    "        tmp_data.append(tmp_teacher)\n",
    "        tmp_data.append(answers[i:i+10])\n",
    "        #print(tmp_data)\n",
    "        break\n",
    "        #print(list(zip(teachers[i:i+1], answers[i:i+10])))\n",
    "    return teachers, answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ニューラルネットワークの構築。\n",
    "class CNN(Chain):\n",
    "    \n",
    "    def __init__(self, n_output):\n",
    "        if(GPU == -1):\n",
    "            super(CNN, self).__init__(\n",
    "                l1=L.Convolution2D(1,20,3),\n",
    "                l2=L.Linear(None, n_output)\n",
    "            )\n",
    "        else:\n",
    "            super(CNN, self).__init__(\n",
    "                l1=L.Convolution2D(1,20,3).to_gpu(),\n",
    "                l2=L.Linear(None, n_output).to_gpu()\n",
    "            )   \n",
    "        \n",
    "    def __call__(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        loss = F.mean_squared_error(y,t)\n",
    "        #loss = F.softmax_cross_entropy(y,t)\n",
    "        data = y.data[:]\n",
    "        accuracy = self.accuracy(data, t)\n",
    "        chainer.reporter.report({'accuracy':accuracy},self)\n",
    "        chainer.reporter.report({'loss':loss},self)\n",
    "        return loss\n",
    "    \n",
    "    def accuracy(self, y, t):\n",
    "        correct = 0\n",
    "        for j in range( 0, len(y) ):\n",
    "            if y[j].size:\n",
    "                for i in range( 0, 3 ):\n",
    "                    if( t[j][y[j].argmax()] ):\n",
    "                        correct += 1\n",
    "                    y[j][y[j].argmax()]= np.amin(y[j])\n",
    "        return correct / (len(y) * 3)\n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "        h1 = F.max_pooling_2d(F.relu(self.l1(x)),2)\n",
    "        return F.softmax(self.l2(h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Updaterを拡張する\n",
    "from chainer import Variable, reporter\n",
    "\n",
    "class LSTMUpdater(training.StandardUpdater):\n",
    "    def __init__(self, data_iter, optimizer, device=None):\n",
    "        super(LSTMUpdater,self).__init__(data_iter, optimizer, device=None)\n",
    "        self.device = device\n",
    "        \n",
    "    def update_core(self):\n",
    "        data_iter = self.get_iterator(\"main\")\n",
    "        optimizer = self.get_optimizer(\"main\")\n",
    "        \n",
    "        batch = data_iter.__next__()\n",
    "        data = chainer.dataset.concat_examples(batch, self.device)\n",
    "        x_batch = data[:][0]\n",
    "        t_batch = data[:][1]\n",
    "        x_batch = np.array(x_batch)\n",
    "        #x_batch = x_batch[:,np.newaxis,:,:]\n",
    "        t_batch = np.array(t_batch)\n",
    "        #print(x_batch)\n",
    "        #x_batch, t_batch = chainer.dataset.concat_examples(batch, self.device)\n",
    "        #optimizer.target.reset_state()           \n",
    "        optimizer.target.cleargrads()\n",
    "        #loss = optimizer.target(Variable(x_batch), Variable(t_batch))\n",
    "        loss = optimizer.target(x_batch, t_batch)\n",
    "        loss.backward()\n",
    "        loss.unchain_backward()                  \n",
    "        optimizer.update() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teachers, answers = data_read( 'numbers.txt', 3)\n",
    "GPU = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n",
      "1250\n",
      "[[0, 0, 0, 0, 1, 0, 1, 1, 0, 0], [0, 1, 0, 1, 0, 0, 1, 0, 0, 0], [0, 2, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
      "[0, 1, 0, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(teachers))\n",
    "print(len(answers))\n",
    "print(teachers[-1])\n",
    "print(answers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250, 1, 3, 10)\n"
     ]
    }
   ],
   "source": [
    "teachers = np.array(teachers)\n",
    "teachers = teachers.astype(np.float32)[:,np.newaxis,:,:]\n",
    "print(teachers.shape)\n",
    "answers = np.array(answers)\n",
    "answers = answers.astype(np.float32)\n",
    "data = tuple_dataset.TupleDataset(teachers, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           0.31152     0.306792              0.270915       0.281481                  0.162192      \n",
      "\u001b[J2           0.312805    0.308513              0.274747       0.288889                  0.674035      \n",
      "\u001b[J3           0.315448    0.311238              0.277778       0.291358                  1.21433       \n",
      "\u001b[J4           0.317352    0.313723              0.277124       0.27284                   1.78129       \n",
      "\u001b[J5           0.317342    0.312571              0.285185       0.265432                  2.24339       \n",
      "\u001b[J6           0.315339    0.313725              0.285859       0.260494                  2.80617       \n",
      "\u001b[J7           0.315396    0.313883              0.283333       0.269136                  3.33968       \n",
      "\u001b[J8           0.315516    0.314467              0.281818       0.265432                  3.90822       \n",
      "\u001b[J9           0.316906    0.315037              0.285185       0.277778                  4.32191       \n",
      "\u001b[J10          0.315542    0.315654              0.281373       0.271605                  4.86763       \n"
     ]
    }
   ],
   "source": [
    "#　教師データのtupleを作成する\n",
    "#data = list(zip(teachers, answers))\n",
    "\n",
    "#data = np.array(data)\n",
    "N = len(data)\n",
    "n_batchsize = 30\n",
    "n_epoch = 10\n",
    "\n",
    "#モデルを使う準備。オブジェクトを生成\n",
    "n_output = 10\n",
    "model = CNN(n_output)\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "#学習用データと検証用データに分ける\n",
    "train, test = chainer.datasets.split_dataset_random(data, int(N * 0.8))\n",
    "train_iter = chainer.iterators.SerialIterator(train, n_batchsize, shuffle=False)\n",
    "test_iter = chainer.iterators.SerialIterator(test, n_batchsize, repeat=False, shuffle=False)\n",
    "updater = LSTMUpdater(train_iter, optimizer, device=GPU)\n",
    "trainer = training.Trainer(updater, (n_epoch, \"epoch\"), out=\"result\")\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=GPU))\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.PrintReport( [\"epoch\", \"main/loss\", \"validation/main/loss\", \"main/accuracy\", \"validation/main/accuracy\", \"elapsed_time\"])) # エポック、学習損失、テスト損失、学習正解率、テスト正解率、経過時間\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
